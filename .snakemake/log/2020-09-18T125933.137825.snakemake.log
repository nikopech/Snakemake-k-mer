Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 4
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	1	best_fit
	3	k_mer_files
	5

[Fri Sep 18 12:59:33 2020]
Job 3: Call files/complete_genome_SARS-CoV-2.fasta with k=6

[Fri Sep 18 13:01:29 2020]
Finished job 3.
1 of 5 steps (20%) done

[Fri Sep 18 13:01:29 2020]
Job 1: Call files/complete_genome_SARS-CoV-2.fasta with k=4

[Fri Sep 18 13:03:16 2020]
Finished job 1.
2 of 5 steps (40%) done

[Fri Sep 18 13:03:16 2020]
Job 2: Call files/complete_genome_SARS-CoV-2.fasta with k=5

Terminating processes on user request, this might take some time.
[Fri Sep 18 13:05:04 2020]
Error in rule k_mer_files:
    jobid: 2
    output: results/complete_genome_SARS-CoV-2_result_5.txt
    shell:
        
			start=$(date +%s.%N)
			python k-mer.py 5 files/complete_genome_SARS-CoV-2.fasta results/complete_genome_SARS-CoV-2_result_5.txt 
			dur=$(echo "$(date +%s.%N) - $start" | bc) 
			printf "%.6f\n" $dur >> "time.txt" 
			
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Complete log: /home/togkousa/INEB work/snakemake/Snakemake-k-mer/.snakemake/log/2020-09-18T125933.137825.snakemake.log
